{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753f842e",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c86154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63d728",
   "metadata": {},
   "source": [
    "### PreProcessing Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4a4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_preprocess(img_address):\n",
    "    img = cv.imread(img_address)\n",
    "\n",
    "    h , w = img.shape[:2] # Width and Height of Image \n",
    "    \n",
    "    proc_img = cv.dnn.blobFromImage(img ,size = (416,416) , scalefactor = 1/255 , crop = False ,swapRB = True )\n",
    "    \n",
    "    return img , proc_img , w , h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b455e",
   "metadata": {},
   "source": [
    "### Load Weights, Configs and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d05f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_and_labels(weights , configs , label_names):\n",
    "    \n",
    "    labels = open(label_names).read().strip().split(\"\\n\")\n",
    "        \n",
    "    net = cv.dnn.readNet(weights , configs)\n",
    "    \n",
    "    return labels , net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaba5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(pre_processed_image, w , h , net , labels):\n",
    "    \n",
    "    net.setInput(pre_processed_image)\n",
    "#     layers_name = net.getLayerNames()\n",
    "#     print(layers_name)\n",
    "    out_layers = ['yolo_82' , 'yolo_94' , 'yolo_106']\n",
    "    \n",
    "    prediction = net.forward(out_layers)\n",
    "    \n",
    "    return (prediction)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc3caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_process(predictions , w , h ):\n",
    "    ID_classes = []\n",
    "    confidenses = []\n",
    "    b_boxes = []\n",
    "        \n",
    "    for layer in predictions:\n",
    "        for detectedObj in layer:\n",
    "            prob_classes = detectedObj[5:] #Classes with Probabilities\n",
    "            \n",
    "            max_index = np.argmax(prob_classes) # find index with max Value(Probability) \n",
    "            \n",
    "            conf = prob_classes[max_index] # extract Class confidence\n",
    "            \n",
    "            if conf>0.3 : \n",
    "                box = detectedObj[0:4] * np.array([w,h,w,h]) # to convert normalized Image to original sizes\n",
    "                \n",
    "                (centerX , centerY , width , height ) = box.astype('int')\n",
    "                print(centerX , centerY , width , height)\n",
    "                x = int(centerX - width / 2 )\n",
    "                y = int(centerY - height / 2 )\n",
    "\n",
    "                ID_classes.append(max_index)\n",
    "                confidenses.append(float(conf))\n",
    "                b_boxes.append([x , y , int(width) , int(height)])\n",
    "                \n",
    "    return ID_classes , confidenses , b_boxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf8b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(img ,ID_classes , confidenses , b_boxes , labels):\n",
    "    \n",
    "    idxs = cv.dnn.NMSBoxes(b_boxes , confidenses , 0.3 , 0.5 )\n",
    "    \n",
    "    for i in idxs.flatten():\n",
    "        (x , y) = b_boxes[i][0] , b_boxes[i][1]\n",
    "        (w , h) = b_boxes[i][2] , b_boxes[i][3]\n",
    "        \n",
    "        cv.rectangle(img , (x , y) , (x + w , y + h) , (0,255,0) , 1 )\n",
    "        text = \"{} : {:.2f}\".format(labels[ID_classes[i]] , confidenses[i])\n",
    "        cv.putText(img, text , (x , y-10) , cv.FONT_HERSHEY_SIMPLEX , 0.5 , (0,255,0) , 2)\n",
    "        \n",
    "    cv.imshow('myWin' , img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 191 33 41\n",
      "67 205 52 51\n",
      "67 204 64 44\n",
      "65 206 61 58\n",
      "217 204 36 29\n",
      "217 203 46 29\n",
      "67 212 48 47\n",
      "65 211 65 45\n",
      "64 209 61 56\n",
      "357 217 81 46\n",
      "358 217 84 48\n",
      "278 227 27 82\n",
      "278 228 34 101\n",
      "358 220 81 44\n",
      "357 220 82 49\n",
      "278 232 29 84\n",
      "278 231 37 96\n",
      "146 117 8 18\n",
      "169 135 7 13\n",
      "441 176 34 12\n",
      "442 176 35 12\n",
      "26 194 10 26\n",
      "196 195 20 14\n",
      "313 196 11 29\n",
      "141 201 32 24\n",
      "217 200 35 21\n",
      "314 199 11 28\n",
      "216 205 36 24\n",
      "492 222 15 25\n"
     ]
    }
   ],
   "source": [
    "img , proc_img , w , h = load_data_preprocess('images/street.jpg')\n",
    "\n",
    "labels , net = read_model_and_labels('yolo_files/yolov3.weights' , 'yolo_files/yolov3.cfg' ,'yolo_files/coco.names' )\n",
    "\n",
    "predictions = inference(proc_img , w , h , net , labels)\n",
    "\n",
    "ID_classes , confidenses , b_boxes = final_process(predictions , w , h )\n",
    "\n",
    "show_result(img ,ID_classes , confidenses , b_boxes , labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
